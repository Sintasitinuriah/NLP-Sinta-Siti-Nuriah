{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqLnh/rJJjdSR/+B3KrmU9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import json\n","import string\n","import random\n","import nltk\n","nltk.download('omw-1.4')\n","import numpy as num\n","from nltk.stem import WordNetLemmatizer # It has the ability to lemmatize.\n","import tensorflow as tensorF # A multidimensional array of elements is represented by this symbol.\n","from tensorflow.keras import Sequential # Sequential groups a linear stack of layers into a tf.keras.Model\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","nltk.download(\"punkt\")# required package for tokenization\n","nltk.download(\"wordnet\")# word database"],"metadata":{"id":"FhfO0YtHpOwn","executionInfo":{"status":"ok","timestamp":1673239211566,"user_tz":-420,"elapsed":1550,"user":{"displayName":"10219008 Sinta Nuriah","userId":"02091276461257992721"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d50caf2-b09b-4da4-9a0e-e76d892b76e6"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["ourData = {\"ourIntents\": [\n","\n","             {\"tag\": \"greeting\",\n","              \"patterns\": [ \"Hi\", \"Hello\", \"Hey\"],\n","              \"responses\": [\"Hi Toko sinta siap melayani anda\", \"Hello, selamat berbelanja\", \"Hi, semoga menyenangkan ya berbelanjanya :)\"],\n","             },\n","              {\"tag\": \"jadwal\",\n","              \"patterns\": [ \"buka\", \"tutup\", \"kapan bukanya?\", \"waktu buka\", \"waktu tutup\", \"tutup kapan?\"],\n","              \"responses\": [\"Toko buka senin-jum'at 08.00-16.00\", \"toko tutup pada sabtu-minggu\"]\n","             },\n","             {\"tag\": \"alamat\",\n","              \"patterns\": [\"toko\",\"dimana alamatnya\", \"alamat toko dimana?\", \"toko offlinenya dimana?\"],\n","              \"responses\": [\"kp. gandok, Rt 01 Rw 11 Cipakat Singparna Tasikmalaya\"]\n","             },\n","             {\"tag\": \"price\",\n","              \"patterns\": [\"harga baju\", \"harga celana\", \"harga jilbab\", \"baju\", \"celana\", \"jilbab\"],\n","              \"responses\": [\"harga mulai 100000-245000\", \"harga mulai 75000-225000\", \"harga mulai 25000-80000\"]\n","             },\n","             {\"tag\": \"ketersediaan\",\n","              \"patterns\": [\"ada\", \"tidak ada\"],\n","              \"responses\": [\"semua barang tersedia\", \"tidak ada barang kosong\"]\n","             },\n","              {\"tag\": \"beli\",\n","              \"patterns\": [\"beli\", \"nanti\", \"tidak jadi\"],\n","              \"responses\": [\"Terimkasih telah mengunjungi toko kami\"]\n","             },\n","             {\"tag\": \"goodbye\",\n","              \"patterns\": [ \"bye\", \"later\"],\n","              \"responses\": [\"Bye\", \"take care\"]\n","             }\n","]}"],"metadata":{"id":"lhZhbtPwpHYq","executionInfo":{"status":"ok","timestamp":1673239419151,"user_tz":-420,"elapsed":324,"user":{"displayName":"10219008 Sinta Nuriah","userId":"02091276461257992721"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["lm = WordNetLemmatizer() #for getting words\n","# lists\n","ourClasses = []\n","newWords = []\n","documentX = []\n","documentY = []\n","# Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n","for intent in ourData[\"ourIntents\"]:\n","    for pattern in intent[\"patterns\"]:\n","        ournewTkns = nltk.word_tokenize(pattern)# tokenize the patterns\n","        newWords.extend(ournewTkns)# extends the tokens\n","        documentX.append(pattern)\n","        documentY.append(intent[\"tag\"])\n","\n","\n","    if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n","        ourClasses.append(intent[\"tag\"])\n","\n","newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n","newWords = sorted(set(newWords))# sorting words\n","ourClasses = sorted(set(ourClasses))# sorting classes"],"metadata":{"id":"UqFN92Owxu0o","executionInfo":{"status":"ok","timestamp":1673239231824,"user_tz":-420,"elapsed":342,"user":{"displayName":"10219008 Sinta Nuriah","userId":"02091276461257992721"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["trainingData = [] # training list array\n","outEmpty = [0] * len(ourClasses)\n","# bow model\n","for idx, doc in enumerate(documentX):\n","    bagOfwords = []\n","    text = lm.lemmatize(doc.lower())\n","    for word in newWords:\n","        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n","\n","    outputRow = list(outEmpty)\n","    outputRow[ourClasses.index(documentY[idx])] = 1\n","    trainingData.append([bagOfwords, outputRow])\n","\n","random.shuffle(trainingData)\n","trainingData = num.array(trainingData, dtype=object)# coverting our data into an array afterv shuffling\n","\n","x = num.array(list(trainingData[:, 0]))# first trainig phase\n","y = num.array(list(trainingData[:, 1]))# second training phase"],"metadata":{"id":"FCh0l3aOx8EO","executionInfo":{"status":"ok","timestamp":1673239235550,"user_tz":-420,"elapsed":510,"user":{"displayName":"10219008 Sinta Nuriah","userId":"02091276461257992721"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["iShape = (len(x[0]),)\n","oShape = len(y[0])\n","# parameter definition\n","ourNewModel = Sequential()\n","# In the case of a simple stack of layers, a Sequential model is appropriate\n","\n","# Dense function adds an output layer\n","ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n","# The activation function in a neural network is in charge of converting the node's summed weighted input into activation of the node or output for the input in question\n","ourNewModel.add(Dropout(0.5))\n","# Dropout is used to enhance visual perception of input neurons\n","ourNewModel.add(Dense(64, activation=\"relu\"))\n","ourNewModel.add(Dropout(0.3))\n","ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n","# below is a callable that returns the value to be used with no arguments\n","md = tensorF.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n","# Below line improves the numerical stability and pushes the computation of the probability distribution into the categorical crossentropy loss function.\n","ourNewModel.compile(loss='categorical_crossentropy',\n","              optimizer=md,\n","              metrics=[\"accuracy\"])\n","# Output the model in summary\n","print(ourNewModel.summary())\n","# Whilst training your Nural Network, you have the option of making the output verbose or simple.\n","ourNewModel.fit(x, y, epochs=200, verbose=1)\n","# By epochs, we mean the number of times you repeat a training set."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BBhIJ1LyA1E","executionInfo":{"status":"ok","timestamp":1673239243513,"user_tz":-420,"elapsed":6309,"user":{"displayName":"10219008 Sinta Nuriah","userId":"02091276461257992721"}},"outputId":"1e5e5964-55f3-4464-83a1-dc0c6de87127"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_11\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_33 (Dense)            (None, 128)               2816      \n","                                                                 \n"," dropout_22 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_34 (Dense)            (None, 64)                8256      \n","                                                                 \n"," dropout_23 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_35 (Dense)            (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 11,462\n","Trainable params: 11,462\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/200\n","1/1 [==============================] - 1s 608ms/step - loss: 1.7623 - accuracy: 0.1304\n","Epoch 2/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.6801 - accuracy: 0.4348\n","Epoch 3/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.5543 - accuracy: 0.5652\n","Epoch 4/200\n","1/1 [==============================] - 0s 14ms/step - loss: 1.3508 - accuracy: 0.6522\n","Epoch 5/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2130 - accuracy: 0.6522\n","Epoch 6/200\n","1/1 [==============================] - 0s 12ms/step - loss: 1.1093 - accuracy: 0.6957\n","Epoch 7/200\n","1/1 [==============================] - 0s 14ms/step - loss: 0.9756 - accuracy: 0.6957\n","Epoch 8/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.8524 - accuracy: 0.6087\n","Epoch 9/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.7336 - accuracy: 0.7391\n","Epoch 10/200\n","1/1 [==============================] - 0s 17ms/step - loss: 0.6013 - accuracy: 0.7391\n","Epoch 11/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.6439 - accuracy: 0.7391\n","Epoch 12/200\n","1/1 [==============================] - 0s 19ms/step - loss: 0.4314 - accuracy: 0.8261\n","Epoch 13/200\n","1/1 [==============================] - 0s 14ms/step - loss: 0.4095 - accuracy: 0.9130\n","Epoch 14/200\n","1/1 [==============================] - 0s 15ms/step - loss: 0.3413 - accuracy: 0.8696\n","Epoch 15/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.3317 - accuracy: 0.9565\n","Epoch 16/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1899 - accuracy: 1.0000\n","Epoch 17/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.1150 - accuracy: 1.0000\n","Epoch 18/200\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0996 - accuracy: 1.0000\n","Epoch 19/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 1.0000\n","Epoch 20/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0470 - accuracy: 1.0000\n","Epoch 21/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 1.0000\n","Epoch 22/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0542 - accuracy: 1.0000\n","Epoch 23/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0128 - accuracy: 1.0000\n","Epoch 24/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0223 - accuracy: 1.0000\n","Epoch 25/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 1.0000\n","Epoch 26/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0435 - accuracy: 1.0000\n","Epoch 27/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0137 - accuracy: 1.0000\n","Epoch 28/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 29/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0083 - accuracy: 1.0000\n","Epoch 30/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 31/200\n","1/1 [==============================] - 0s 21ms/step - loss: 0.0107 - accuracy: 1.0000\n","Epoch 32/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0372 - accuracy: 1.0000\n","Epoch 33/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 34/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 35/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 1.0000\n","Epoch 36/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 37/200\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 38/200\n","1/1 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 39/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 1.0000\n","Epoch 40/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 1.0000\n","Epoch 41/200\n","1/1 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 42/200\n","1/1 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 43/200\n","1/1 [==============================] - 0s 12ms/step - loss: 4.5341e-04 - accuracy: 1.0000\n","Epoch 44/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 45/200\n","1/1 [==============================] - 0s 16ms/step - loss: 9.3583e-04 - accuracy: 1.0000\n","Epoch 46/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 1.0000\n","Epoch 47/200\n","1/1 [==============================] - 0s 13ms/step - loss: 3.6295e-04 - accuracy: 1.0000\n","Epoch 48/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 49/200\n","1/1 [==============================] - 0s 14ms/step - loss: 8.2461e-04 - accuracy: 1.0000\n","Epoch 50/200\n","1/1 [==============================] - 0s 12ms/step - loss: 6.5806e-04 - accuracy: 1.0000\n","Epoch 51/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 52/200\n","1/1 [==============================] - 0s 18ms/step - loss: 7.1333e-04 - accuracy: 1.0000\n","Epoch 53/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.5820e-04 - accuracy: 1.0000\n","Epoch 54/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 55/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 56/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 57/200\n","1/1 [==============================] - 0s 13ms/step - loss: 7.6398e-04 - accuracy: 1.0000\n","Epoch 58/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 59/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.5390e-04 - accuracy: 1.0000\n","Epoch 60/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 61/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 62/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 63/200\n","1/1 [==============================] - 0s 14ms/step - loss: 5.9291e-04 - accuracy: 1.0000\n","Epoch 64/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 65/200\n","1/1 [==============================] - 0s 15ms/step - loss: 1.0605e-04 - accuracy: 1.0000\n","Epoch 66/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 67/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.2697e-04 - accuracy: 1.0000\n","Epoch 68/200\n","1/1 [==============================] - 0s 19ms/step - loss: 0.0048 - accuracy: 1.0000\n","Epoch 69/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.3916e-04 - accuracy: 1.0000\n","Epoch 70/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.5002e-04 - accuracy: 1.0000\n","Epoch 71/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 72/200\n","1/1 [==============================] - 0s 13ms/step - loss: 5.5132e-04 - accuracy: 1.0000\n","Epoch 73/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 74/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 75/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 76/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.7121e-04 - accuracy: 1.0000\n","Epoch 77/200\n","1/1 [==============================] - 0s 8ms/step - loss: 8.1518e-05 - accuracy: 1.0000\n","Epoch 78/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 79/200\n","1/1 [==============================] - 0s 10ms/step - loss: 9.0324e-04 - accuracy: 1.0000\n","Epoch 80/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.4212e-04 - accuracy: 1.0000\n","Epoch 81/200\n","1/1 [==============================] - 0s 13ms/step - loss: 3.7117e-05 - accuracy: 1.0000\n","Epoch 82/200\n","1/1 [==============================] - 0s 8ms/step - loss: 6.6792e-04 - accuracy: 1.0000\n","Epoch 83/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.0742e-04 - accuracy: 1.0000\n","Epoch 84/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.7291e-04 - accuracy: 1.0000\n","Epoch 85/200\n","1/1 [==============================] - 0s 13ms/step - loss: 7.4280e-04 - accuracy: 1.0000\n","Epoch 86/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.7018e-04 - accuracy: 1.0000\n","Epoch 87/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 88/200\n","1/1 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 1.0000\n","Epoch 89/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.5252e-04 - accuracy: 1.0000\n","Epoch 90/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 91/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2807e-04 - accuracy: 1.0000\n","Epoch 92/200\n","1/1 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 93/200\n","1/1 [==============================] - 0s 12ms/step - loss: 9.8301e-05 - accuracy: 1.0000\n","Epoch 94/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 95/200\n","1/1 [==============================] - 0s 10ms/step - loss: 8.2443e-05 - accuracy: 1.0000\n","Epoch 96/200\n","1/1 [==============================] - 0s 13ms/step - loss: 2.9492e-04 - accuracy: 1.0000\n","Epoch 97/200\n","1/1 [==============================] - 0s 10ms/step - loss: 8.8529e-04 - accuracy: 1.0000\n","Epoch 98/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.3174e-04 - accuracy: 1.0000\n","Epoch 99/200\n","1/1 [==============================] - 0s 13ms/step - loss: 2.1421e-04 - accuracy: 1.0000\n","Epoch 100/200\n","1/1 [==============================] - 0s 11ms/step - loss: 1.0940e-04 - accuracy: 1.0000\n","Epoch 101/200\n","1/1 [==============================] - 0s 11ms/step - loss: 8.1615e-05 - accuracy: 1.0000\n","Epoch 102/200\n","1/1 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 103/200\n","1/1 [==============================] - 0s 12ms/step - loss: 9.4584e-04 - accuracy: 1.0000\n","Epoch 104/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.1975e-05 - accuracy: 1.0000\n","Epoch 105/200\n","1/1 [==============================] - 0s 16ms/step - loss: 1.5321e-04 - accuracy: 1.0000\n","Epoch 106/200\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 107/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 108/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 1.0000\n","Epoch 109/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.6909e-04 - accuracy: 1.0000\n","Epoch 110/200\n","1/1 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 111/200\n","1/1 [==============================] - 0s 12ms/step - loss: 2.0643e-05 - accuracy: 1.0000\n","Epoch 112/200\n","1/1 [==============================] - 0s 11ms/step - loss: 5.3934e-04 - accuracy: 1.0000\n","Epoch 113/200\n","1/1 [==============================] - 0s 16ms/step - loss: 2.0393e-04 - accuracy: 1.0000\n","Epoch 114/200\n","1/1 [==============================] - 0s 17ms/step - loss: 8.4437e-04 - accuracy: 1.0000\n","Epoch 115/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2456e-04 - accuracy: 1.0000\n","Epoch 116/200\n","1/1 [==============================] - 0s 8ms/step - loss: 4.8444e-04 - accuracy: 1.0000\n","Epoch 117/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.6912e-04 - accuracy: 1.0000\n","Epoch 118/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 119/200\n","1/1 [==============================] - 0s 13ms/step - loss: 2.4005e-05 - accuracy: 1.0000\n","Epoch 120/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.4950e-04 - accuracy: 1.0000\n","Epoch 121/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 122/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 1.0000\n","Epoch 123/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0061 - accuracy: 1.0000\n","Epoch 124/200\n","1/1 [==============================] - 0s 10ms/step - loss: 9.4851e-04 - accuracy: 1.0000\n","Epoch 125/200\n","1/1 [==============================] - 0s 32ms/step - loss: 5.6876e-04 - accuracy: 1.0000\n","Epoch 126/200\n","1/1 [==============================] - 0s 18ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 127/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0172 - accuracy: 1.0000\n","Epoch 128/200\n","1/1 [==============================] - 0s 84ms/step - loss: 9.7179e-05 - accuracy: 1.0000\n","Epoch 129/200\n","1/1 [==============================] - 0s 23ms/step - loss: 4.8162e-04 - accuracy: 1.0000\n","Epoch 130/200\n","1/1 [==============================] - 0s 71ms/step - loss: 9.5795e-05 - accuracy: 1.0000\n","Epoch 131/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 132/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2114e-04 - accuracy: 1.0000\n","Epoch 133/200\n","1/1 [==============================] - 0s 11ms/step - loss: 2.5196e-04 - accuracy: 1.0000\n","Epoch 134/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 135/200\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 136/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.3181e-04 - accuracy: 1.0000\n","Epoch 137/200\n","1/1 [==============================] - 0s 13ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 138/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.1403e-04 - accuracy: 1.0000\n","Epoch 139/200\n","1/1 [==============================] - 0s 8ms/step - loss: 2.4922e-05 - accuracy: 1.0000\n","Epoch 140/200\n","1/1 [==============================] - 0s 9ms/step - loss: 9.4691e-06 - accuracy: 1.0000\n","Epoch 141/200\n","1/1 [==============================] - 0s 12ms/step - loss: 8.5556e-05 - accuracy: 1.0000\n","Epoch 142/200\n","1/1 [==============================] - 0s 9ms/step - loss: 8.0121e-05 - accuracy: 1.0000\n","Epoch 143/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.3796e-05 - accuracy: 1.0000\n","Epoch 144/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.2049e-04 - accuracy: 1.0000\n","Epoch 145/200\n","1/1 [==============================] - 0s 12ms/step - loss: 1.5994e-05 - accuracy: 1.0000\n","Epoch 146/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.3719e-04 - accuracy: 1.0000\n","Epoch 147/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.8068e-04 - accuracy: 1.0000\n","Epoch 148/200\n","1/1 [==============================] - 0s 12ms/step - loss: 5.7096e-04 - accuracy: 1.0000\n","Epoch 149/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.2941e-04 - accuracy: 1.0000\n","Epoch 150/200\n","1/1 [==============================] - 0s 13ms/step - loss: 6.8568e-04 - accuracy: 1.0000\n","Epoch 151/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.2641e-05 - accuracy: 1.0000\n","Epoch 152/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.1961e-04 - accuracy: 1.0000\n","Epoch 153/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.4809e-04 - accuracy: 1.0000\n","Epoch 154/200\n","1/1 [==============================] - 0s 13ms/step - loss: 2.8828e-04 - accuracy: 1.0000\n","Epoch 155/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.3687e-05 - accuracy: 1.0000\n","Epoch 156/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.8457e-04 - accuracy: 1.0000\n","Epoch 157/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.1319e-05 - accuracy: 1.0000\n","Epoch 158/200\n","1/1 [==============================] - 0s 13ms/step - loss: 4.9537e-05 - accuracy: 1.0000\n","Epoch 159/200\n","1/1 [==============================] - 0s 11ms/step - loss: 4.6340e-04 - accuracy: 1.0000\n","Epoch 160/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.4736e-06 - accuracy: 1.0000\n","Epoch 161/200\n","1/1 [==============================] - 0s 13ms/step - loss: 7.4460e-04 - accuracy: 1.0000\n","Epoch 162/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.7474e-05 - accuracy: 1.0000\n","Epoch 163/200\n","1/1 [==============================] - 0s 14ms/step - loss: 6.6213e-05 - accuracy: 1.0000\n","Epoch 164/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.7641e-05 - accuracy: 1.0000\n","Epoch 165/200\n","1/1 [==============================] - 0s 11ms/step - loss: 3.0466e-05 - accuracy: 1.0000\n","Epoch 166/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.6745e-04 - accuracy: 1.0000\n","Epoch 167/200\n","1/1 [==============================] - 0s 12ms/step - loss: 3.9246e-05 - accuracy: 1.0000\n","Epoch 168/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.7741e-04 - accuracy: 1.0000\n","Epoch 169/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 170/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.1475e-04 - accuracy: 1.0000\n","Epoch 171/200\n","1/1 [==============================] - 0s 16ms/step - loss: 2.0830e-04 - accuracy: 1.0000\n","Epoch 172/200\n","1/1 [==============================] - 0s 9ms/step - loss: 3.2752e-05 - accuracy: 1.0000\n","Epoch 173/200\n","1/1 [==============================] - 0s 9ms/step - loss: 2.2632e-05 - accuracy: 1.0000\n","Epoch 174/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.1061e-04 - accuracy: 1.0000\n","Epoch 175/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.8948e-04 - accuracy: 1.0000\n","Epoch 176/200\n","1/1 [==============================] - 0s 21ms/step - loss: 7.4759e-05 - accuracy: 1.0000\n","Epoch 177/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.4113e-05 - accuracy: 1.0000\n","Epoch 178/200\n","1/1 [==============================] - 0s 12ms/step - loss: 5.1345e-05 - accuracy: 1.0000\n","Epoch 179/200\n","1/1 [==============================] - 0s 14ms/step - loss: 9.0571e-05 - accuracy: 1.0000\n","Epoch 180/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 181/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.3974e-05 - accuracy: 1.0000\n","Epoch 182/200\n","1/1 [==============================] - 0s 10ms/step - loss: 8.9010e-05 - accuracy: 1.0000\n","Epoch 183/200\n","1/1 [==============================] - 0s 13ms/step - loss: 3.4786e-04 - accuracy: 1.0000\n","Epoch 184/200\n","1/1 [==============================] - 0s 9ms/step - loss: 1.0911e-04 - accuracy: 1.0000\n","Epoch 185/200\n","1/1 [==============================] - 0s 10ms/step - loss: 1.1489e-04 - accuracy: 1.0000\n","Epoch 186/200\n","1/1 [==============================] - 0s 12ms/step - loss: 2.7246e-04 - accuracy: 1.0000\n","Epoch 187/200\n","1/1 [==============================] - 0s 10ms/step - loss: 8.5323e-05 - accuracy: 1.0000\n","Epoch 188/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.8130e-05 - accuracy: 1.0000\n","Epoch 189/200\n","1/1 [==============================] - 0s 11ms/step - loss: 9.2763e-05 - accuracy: 1.0000\n","Epoch 190/200\n","1/1 [==============================] - 0s 10ms/step - loss: 6.0993e-05 - accuracy: 1.0000\n","Epoch 191/200\n","1/1 [==============================] - 0s 14ms/step - loss: 5.5311e-04 - accuracy: 1.0000\n","Epoch 192/200\n","1/1 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 193/200\n","1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 194/200\n","1/1 [==============================] - 0s 12ms/step - loss: 3.3529e-04 - accuracy: 1.0000\n","Epoch 195/200\n","1/1 [==============================] - 0s 13ms/step - loss: 2.5812e-04 - accuracy: 1.0000\n","Epoch 196/200\n","1/1 [==============================] - 0s 10ms/step - loss: 3.5473e-04 - accuracy: 1.0000\n","Epoch 197/200\n","1/1 [==============================] - 0s 10ms/step - loss: 7.4394e-04 - accuracy: 1.0000\n","Epoch 198/200\n","1/1 [==============================] - 0s 10ms/step - loss: 2.1403e-05 - accuracy: 1.0000\n","Epoch 199/200\n","1/1 [==============================] - 0s 11ms/step - loss: 4.3284e-05 - accuracy: 1.0000\n","Epoch 200/200\n","1/1 [==============================] - 0s 9ms/step - loss: 5.4144e-04 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3b66d17f70>"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["def ourText(text):\n","  newtkns = nltk.word_tokenize(text)\n","  newtkns = [lm.lemmatize(word) for word in newtkns]\n","  return newtkns\n","\n","def wordBag(text, vocab):\n","  newtkns = ourText(text)\n","  bagOwords = [0] * len(vocab)\n","  for w in newtkns:\n","    for idx, word in enumerate(vocab):\n","      if word == w:\n","        bagOwords[idx] = 1\n","  return num.array(bagOwords)\n","\n","def Pclass(text, vocab, labels):\n","  bagOwords = wordBag(text, vocab)\n","  ourResult = ourNewModel.predict(num.array([bagOwords]))[0]\n","  newThresh = 0.2\n","  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n","\n","  yp.sort(key=lambda x: x[1], reverse=True)\n","  newList = []\n","  for r in yp:\n","    newList.append(labels[r[0]])\n","  return newList\n","\n","def getRes(firstlist, fJson):\n","  tag = firstlist[0]\n","  listOfIntents = fJson[\"ourIntents\"]\n","  for i in listOfIntents:\n","    if i[\"tag\"] == tag:\n","      ourResult = random.choice(i[\"responses\"])\n","      break\n","  return ourResult"],"metadata":{"id":"9ZZmeXezyECe","executionInfo":{"status":"ok","timestamp":1673239243514,"user_tz":-420,"elapsed":31,"user":{"displayName":"10219008 Sinta Nuriah","userId":"02091276461257992721"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["while True:\n","    newMessage = input(\"\")\n","    intents = Pclass(newMessage, newWords, ourClasses)\n","    ourResult = getRes(intents, ourData)\n","    print(ourResult)\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":710},"id":"d3kujkiGyOuy","executionInfo":{"status":"error","timestamp":1673239310519,"user_tz":-420,"elapsed":65253,"user":{"displayName":"10219008 Sinta Nuriah","userId":"02091276461257992721"}},"outputId":"e57c0019-d4bc-45c9-c85e-f01147fb62b3"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["hello\n","1/1 [==============================] - 0s 61ms/step\n","Hi, semoga menyenangkan ya berbelanjanya :)\n","ada\n","1/1 [==============================] - 0s 22ms/step\n","tidak ada barang kosong\n","baju\n","1/1 [==============================] - 0s 32ms/step\n","harga mulai 25000-80000\n","celana\n","1/1 [==============================] - 0s 23ms/step\n","harga mulai 100000-245000\n","alamat\n","1/1 [==============================] - 0s 23ms/step\n","kp. gandok, Rt 01 Rw 11 Cipakat Singparna Tasikmalaya\n","bye\n","1/1 [==============================] - 0s 23ms/step\n","take care\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-77-b6a68364f202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnewMessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mourClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mourResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mourData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mourResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]}]}